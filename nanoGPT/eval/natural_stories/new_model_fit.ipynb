{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:35:09.505083Z",
     "start_time": "2024-07-23T20:35:09.495847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import make_scorer\n",
    " \n",
    "import pickle\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GPT2Tokenizer\n"
   ],
   "id": "f19323e5fe99d33b",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-23T20:35:11.344866Z",
     "start_time": "2024-07-23T20:35:11.318373Z"
    }
   },
   "source": [
    "def load_tokenizer(data_dir):\n",
    "    \"\"\"\n",
    "    Load tokenizer for natural stories evaluation.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The directory path where the tokenizer data is stored.\n",
    "\n",
    "    Returns:\n",
    "        tokenizer (Tokenizer): The loaded tokenizer object.\n",
    "\n",
    "    Raises:\n",
    "        NotImplementedError: If stoi/itos is not supported or found.\n",
    "\n",
    "    \"\"\"\n",
    "    meta_path = os.path.join(data_dir, 'meta.pkl')\n",
    "    load_meta = os.path.exists(meta_path)\n",
    "    if load_meta:\n",
    "        with open(meta_path, 'rb') as f:\n",
    "            meta = pickle.load(f)\n",
    "        if meta.get(\"custom_tokenizer\", False):\n",
    "            print(f\"Loading custom tokenizer from {data_dir}\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(data_dir, use_fast=False)\n",
    "        else:\n",
    "            if meta.get(\"stoi\", False):\n",
    "                raise NotImplementedError(\"stoi/itos not supported yet\")\n",
    "            else:\n",
    "                raise NotImplementedError(\"No stoi/itos found\")\n",
    "    else:\n",
    "        print(\"No meta.pkl found, using default GPT-2 tokenizer\")\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "    if not tokenizer.eos_token:\n",
    "        tokenizer.add_special_tokens({\"eos_token\": \"</s>\"})\n",
    "    if not tokenizer.pad_token:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    tokenizer.padding_side = \"left\" #Add if needed?\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def load_RT_data(rt_root=r'naturalstories_RTS'):\n",
    "    \"\"\"\n",
    "    Load the processed RT data from the RT_root directory\n",
    "    :param rt_root: \n",
    "    :return: processsed_RTs, processed_wordinfo, all_stories, where processed RTs are at WorkerId level ...(fill) \n",
    "    \"\"\"\n",
    "    \n",
    "    pr_RTs = pd.read_csv(os.path.join(rt_root,'processed_RTs.tsv'), sep='\\t')\n",
    "    #column Item represents the story number, zone is word analogue to word number in the story. Sort by Item and Zone to get the word order in the story\n",
    "    pr_RTs = pr_RTs.sort_values(by=['item', 'WorkerId', 'zone'])\n",
    "    \n",
    "    pr_wi = pd.read_csv(os.path.join(rt_root,'processed_wordinfo.tsv'), sep='\\t')\n",
    "    pr_wi = pr_wi.sort_values(by=['item', 'zone'])\n",
    "    \n",
    "    all_st = pd.read_csv(os.path.join(rt_root,'all_stories.tok'), sep='\\t')\n",
    "    all_st = all_st.sort_values(by=['item', 'zone'])\n",
    "    \n",
    "    return pr_RTs, pr_wi, all_st\n",
    "\n",
    "def extract_stories_from_df(stories_df):\n",
    "    \"\"\"\n",
    "    Extract stories from the dataframe with id as key and story as value\n",
    "    :param stories_df: \n",
    "    :return: stories: Dictionary with story id as key and story as value\n",
    "    \"\"\"\n",
    "    stories = {}\n",
    "    story_ids = stories_df[\"item\"].unique()\n",
    "    for story_id in story_ids:\n",
    "        story = stories_df[stories_df[\"item\"] == story_id]\n",
    "        story_text = story.sort_values(by=['zone'])['word'].str.cat(sep=' ')\n",
    "        stories[story_id] = story_text\n",
    "\n",
    "    return stories\n",
    "\n",
    "\n",
    "\n",
    "def build_linear_model_kfold(data_df, x_type = \"surprisal\", y_type = \"log\", per_subject=False, subject_id=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Build a kfold crossvalidation linear model to predict RTs from surprisals\n",
    "\n",
    "    Assuming data_df is the right df being passed. If per subject, it needs to be processed_RTs, else processed_wordinfo\n",
    "    :param data_df: Dataframe containing the RTs and surprisals, if per_subject is True, then the dataframe should contain WorkerId.\n",
    "    :param x_type: Choice between only surprisal, or 1 lag or 2 lag, can be surprisal, lag 1, lag 2\n",
    "    :param per_subject: If True, then the model will be built per subject. If False, then the model will be built for all subjects, on mean RTs\n",
    "    :param subject_id: If per_subject is True, then the subject_id should be provided to build the model for that subject\n",
    "    :return: regr: The linear regression model, mse: Mean squared error, r2: R squared value, X_train, X_test, y_train, y_test\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    if per_subject:\n",
    "        if subject_id is None:\n",
    "            raise ValueError(\"subject_id should be provided if per_subject is True\")\n",
    "        data_df = data_df[data_df['WorkerId'] == subject_id]\n",
    "\n",
    "    if x_type == \"surprisal\":\n",
    "        X = data_df[['surprisal']].to_numpy()\n",
    "    elif x_type == \"lag 1\":\n",
    "        X = data_df[[\"surprisal\", 'surprisal_lag_1']].to_numpy()\n",
    "    elif x_type == \"lag 2\":\n",
    "        X = data_df[['surprisal', 'surprisal_lag_1', 'surprisal_lag_2']].to_numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid x_type, should be surprisal, lag 1 or lag 2\")\n",
    "\n",
    "    if per_subject:\n",
    "        y = data_df['RT'].to_numpy()\n",
    "    else:\n",
    "        y = data_df['meanItemRT'].to_numpy() #assuming the right df is passed\n",
    "    \n",
    "    if y_type == \"log\":\n",
    "        y = np.log(y)\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    def custom_correlation_coeff_scorer(y_true, y_pred):\n",
    "        return np.corrcoef(y_true, y_pred)[0][1]\n",
    "    #print(\"X_train shape, X_test shape, y_train shape, y_test shape\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    regr = linear_model.LinearRegression()\n",
    "    #regr.fit(X_train, y_train)\n",
    "    scores = cross_validate(regr, X, y, cv=5, scoring={'r2': 'r2', \n",
    "                                                       'neg_mean_squared_error': 'neg_mean_squared_error', \n",
    "                                                       'neg_root_mean_squared_error': 'neg_root_mean_squared_error',\n",
    "                                                       \"explained_variance\": \"explained_variance\",\n",
    "                                                       \"custom_correlation_coeff_scorer\": make_scorer(custom_correlation_coeff_scorer)}, \n",
    "                            return_train_score=True)    \n",
    "    return scores\n",
    "\n",
    "def all_subject_summary_kfold(processed_RTs, x_type=\"lag 2\"):\n",
    "\n",
    "    subject_id_list = processed_RTs['WorkerId'].unique()\n",
    "    subject_summary = []\n",
    "    \n",
    "    for subject_id in tqdm.tqdm(subject_id_list):\n",
    "\n",
    "        #ignore the subject if the number of data points is less than 1000 (assuming 1 story has atleast 1000 data points)\n",
    "\n",
    "        if len(processed_RTs[processed_RTs['WorkerId'] == subject_id]) < 1000:\n",
    "            continue\n",
    "\n",
    "        scores = build_linear_model_kfold(processed_RTs, x_type=x_type, per_subject=True, subject_id=subject_id)\n",
    "        \n",
    "        subject_summary.append({\"subject_id\": subject_id,\n",
    "                                \"data_points\": len(processed_RTs[processed_RTs['WorkerId'] == subject_id]),\n",
    "                                \"mse_surprisal\": -1*np.mean(scores['test_neg_mean_squared_error']),   \n",
    "                                \"rmse_surprisal\": -1*np.mean(scores['test_neg_root_mean_squared_error']),\n",
    "                                \"r2_surprisal\": np.mean(scores['test_r2']),\n",
    "                                \"explained_variance\": np.mean(scores['test_explained_variance']),\n",
    "                                \"corr_surprisal\": np.mean(scores['test_custom_correlation_coeff_scorer'])})\n",
    "        \n",
    "\n",
    "    return pd.DataFrame(subject_summary)\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:35:45.072583Z",
     "start_time": "2024-07-23T20:35:12.260395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizers_root = r\"/home/abishekthamma/PycharmProjects/masters_thesis/ss-llm/nanoGPT/data\"\n",
    "data_folder = r'babylm_full_bpe_8k'\n",
    "data_dir = os.path.join(tokenizers_root, data_folder)\n",
    "\n",
    "story_surprisal_keys_df = pd.read_csv(\"story_surprisal_keys.csv\")\n",
    "storyword_model_surprisals_df = pd.read_csv(\"storyword_model_surprisals.csv\")\n",
    "\n",
    "#pick a random model_id to test \n",
    "model_id = 6892213\n",
    "tokenizer = load_tokenizer(data_dir)\n",
    "\n",
    "story_surprisals_df  = storyword_model_surprisals_df[storyword_model_surprisals_df['model_id'] == model_id]\n",
    "story_surprisals_df = pd.merge(story_surprisals_df, story_surprisal_keys_df, on='storyword_UID')[[\"item\", \"zone\", \"word\", \"surprisal\"]]\n",
    "\n",
    "processed_RTs, processed_wordinfo, all_stories = load_RT_data(rt_root=r'naturalstories_RTS')\n",
    "stories = extract_stories_from_df(all_stories)\n",
    "\n",
    "processed_RTs = processed_RTs.merge(story_surprisals_df, on=['item', 'zone', 'word'], how='left')\n",
    "    \n",
    "\n",
    "#Add addition columns for the surprisals of the previous 2 words but for in each worker, story separately\n",
    "processed_RTs['surprisal_lag_1'] = processed_RTs.groupby(['item', 'WorkerId'])['surprisal'].shift(1)\n",
    "processed_RTs['surprisal_lag_2'] = processed_RTs.groupby(['item', 'WorkerId'])['surprisal'].shift(2)\n",
    "    \n",
    "\n",
    "#Fill the missing values with the mean surprisal of the word\n",
    "processed_RTs[\"surprisal_lag_1\"] = processed_RTs['surprisal_lag_1'].fillna(processed_RTs.groupby(['item'])['surprisal'].transform('mean'))\n",
    "processed_RTs['surprisal_lag_2'] = processed_RTs['surprisal_lag_2'].fillna(processed_RTs.groupby(['item'])['surprisal'].transform('mean'))\n",
    "\n",
    "#processed_RTs.head()\n",
    "\n",
    "scores_df = all_subject_summary_kfold(processed_RTs, x_type=\"lag 2\")\n",
    "\n",
    "print(scores_df)"
   ],
   "id": "9b3c1a2f76ec36a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading custom tokenizer from /home/abishekthamma/PycharmProjects/masters_thesis/ss-llm/nanoGPT/data/babylm_full_bpe_8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:29<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         subject_id  data_points  mse_surprisal  rmse_surprisal  r2_surprisal  \\\n",
      "0    A117RW2F1MNBQ8         5198       0.078024        0.271054     -1.210958   \n",
      "1    A11AUVZ4MCA7VU        10224       0.094180        0.306308      0.023275   \n",
      "2    A11GA4B4SEYK44         4211       0.077781        0.270245     -0.128370   \n",
      "3    A11KMPAZSE5Q0Q         5199       0.040240        0.196792     -0.077737   \n",
      "4    A127R5QI5OGBIK         5194       0.091215        0.296610     -1.164325   \n",
      "..              ...          ...            ...             ...           ...   \n",
      "159   ASOBUAZ0IQYSJ         4115       0.143625        0.375962     -0.012565   \n",
      "160   AVG2BI8CS5YKX         5033       0.096687        0.303938     -0.611411   \n",
      "161   AWMGC78CSF6YL         3958       0.097738        0.311061      0.003784   \n",
      "162   AWZ3AH7JH0DRO         5033       0.071312        0.263539     -0.146477   \n",
      "163  A3AA8NU3WAJ3ED         2266       0.150780        0.384913     -0.587501   \n",
      "\n",
      "     explained_variance  corr_surprisal  \n",
      "0              0.021384        0.156279  \n",
      "1              0.036040        0.193428  \n",
      "2              0.025997        0.168086  \n",
      "3              0.002180        0.066341  \n",
      "4              0.013693        0.140112  \n",
      "..                  ...             ...  \n",
      "159            0.038630        0.209347  \n",
      "160            0.019883        0.154880  \n",
      "161            0.036120        0.201117  \n",
      "162            0.024190        0.161043  \n",
      "163            0.033687        0.201970  \n",
      "\n",
      "[164 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:39:57.281093Z",
     "start_time": "2024-07-23T20:39:57.251225Z"
    }
   },
   "cell_type": "code",
   "source": "scores_df[\"corr_surprisal\"].mean()",
   "id": "30eecff74fea3542",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1470293678498752"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#pick a random model_id to test \n",
    "model_id = 6892213\n",
    "tokenizer = load_tokenizer(data_dir)\n",
    "\n",
    "\n",
    "story_surprisals_df  = storyword_model_surprisals_df[storyword_model_surprisals_df['model_id'] == model_id]\n",
    "story_surprisals_df = pd.merge(story_surprisals_df, story_surprisal_keys_df, on='storyword_UID')[[\"item\", \"zone\", \"word\", \"surprisal\"]]\n",
    "\n",
    "processed_RTs, processed_wordinfo, all_stories = load_RT_data(rt_root=r'naturalstories_RTS')\n",
    "stories = extract_stories_from_df(all_stories)\n",
    "\n",
    "processed_RTs = processed_RTs.merge(story_surprisals_df, on=['item', 'zone', 'word'], how='left')\n",
    "    \n",
    "\n",
    "#Add addition columns for the surprisals of the previous 2 words but for in each worker, story separately\n",
    "processed_RTs['surprisal_lag_1'] = processed_RTs.groupby(['item', 'WorkerId'])['surprisal'].shift(1)\n",
    "processed_RTs['surprisal_lag_2'] = processed_RTs.groupby(['item', 'WorkerId'])['surprisal'].shift(2)\n",
    "    \n",
    "\n",
    "#Fill the missing values with the mean surprisal of the word\n",
    "processed_RTs[\"surprisal_lag_1\"] = processed_RTs['surprisal_lag_1'].fillna(processed_RTs.groupby(['item'])['surprisal'].transform('mean'))\n",
    "processed_RTs['surprisal_lag_2'] = processed_RTs['surprisal_lag_2'].fillna(processed_RTs.groupby(['item'])['surprisal'].transform('mean'))\n",
    "\n",
    "#processed_RTs.head()\n",
    "\n",
    "scores_df2 = all_subject_summary_kfold(processed_RTs, x_type=\"lag 2\")\n"
   ],
   "id": "e8625213d503b38d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:16:08.036353Z",
     "start_time": "2024-07-23T20:16:08.026560Z"
    }
   },
   "cell_type": "code",
   "source": "story_surprisal_keys_df.head()",
   "id": "6211e321df0d76d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   storyword_UID  item  zone     word  tokens           tokenizer\n",
       "0              0     1     1       If   [333]  babylm_full_bpe_8k\n",
       "1              1     1     2      you   [208]  babylm_full_bpe_8k\n",
       "2              2     1     3     were   [394]  babylm_full_bpe_8k\n",
       "3              3     1     4       to   [196]  babylm_full_bpe_8k\n",
       "4              4     1     5  journey  [4751]  babylm_full_bpe_8k"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storyword_UID</th>\n",
       "      <th>item</th>\n",
       "      <th>zone</th>\n",
       "      <th>word</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokenizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>If</td>\n",
       "      <td>[333]</td>\n",
       "      <td>babylm_full_bpe_8k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>you</td>\n",
       "      <td>[208]</td>\n",
       "      <td>babylm_full_bpe_8k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>were</td>\n",
       "      <td>[394]</td>\n",
       "      <td>babylm_full_bpe_8k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>[196]</td>\n",
       "      <td>babylm_full_bpe_8k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>journey</td>\n",
       "      <td>[4751]</td>\n",
       "      <td>babylm_full_bpe_8k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:16:10.022538Z",
     "start_time": "2024-07-23T20:16:10.014950Z"
    }
   },
   "cell_type": "code",
   "source": "storyword_model_surprisals_df.head()",
   "id": "1a113e88c8410ef1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   model_id  storyword_UID  surprisal\n",
       "0   5445338          20512  13.324539\n",
       "1   5445338          20513   3.733041\n",
       "2   5445338          20514   3.349813\n",
       "3   5445338          20515   2.085532\n",
       "4   5445338          20516  10.150342"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>storyword_UID</th>\n",
       "      <th>surprisal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5445338</td>\n",
       "      <td>20512</td>\n",
       "      <td>13.324539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5445338</td>\n",
       "      <td>20513</td>\n",
       "      <td>3.733041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5445338</td>\n",
       "      <td>20514</td>\n",
       "      <td>3.349813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5445338</td>\n",
       "      <td>20515</td>\n",
       "      <td>2.085532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5445338</td>\n",
       "      <td>20516</td>\n",
       "      <td>10.150342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
